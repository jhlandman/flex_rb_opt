[
["experiment.html", "7 An empirical test using Sourth African equities 7.1 Data and methodology 7.2 Results 7.3 Code", " 7 An empirical test using Sourth African equities In this chapter, we test the various approaches outlined above for constructing risk-based portfolios using South African equity data. There are two sources of variation in this experiment: variation in risk-based portfolio type and variation in estimation risk reduction technique, all combinations of which are outlined in table ??. Each combination of portfolio-technique approach will be referred to as a pair. 7.1 Data and methodology The available data for this experiment are weekly total-returns for all equity stocks included in the Johannesburg Stock Exchange (JSE) All Share Index (ALSI) over the period ranging from the \\(5^{th}\\) January 1996 to the \\(1^{st}\\) November 2019. Weightings of the shares in the ALSI are also available, although this is a monthly series. This historical vector of the weights of the MW portfolio through time is denoted \\(\\hat{w}^{\\text{mw}}_t\\). The investigation uses a rolling estimation window of \\(T = 400\\)3 weekly observations to construct portfolios. Weekly data inputs are used with monthly rebalancing because of the high data volume requirement from chapter 6. The constructed portfolio \\(\\hat{w}_{t_i}\\) will be held out-of-sample over the interval \\([t_i, t_{i + 1}]\\), where \\(t_i\\) denotes a month’s end. The entire holding period is from the \\(30^{th}\\) of September 2003 to the \\(27^{th}\\) of September 2019 a total of 16 years. Portfolios are constructed for two different asset universes; namely, the \\(40\\) largest stocks and the \\(100\\) largest stocks. The separation is to test the effect on portfolio performance of an investor broadening their universe. This methodology is outlined for each rebalancing date: Of the stocks in the ALSI with a data history of at least length \\(T\\), choose the \\(N\\) stocks with the largest market weights. Use the \\(N \\times T\\) matrix of sample returns to find asset weights for the relevant portfolio-technique pair. Hold the found portfolio \\(\\hat{w}\\) for one month, record the returns \\(\\hat{r}\\), and calculate the portfolio turnover. This experiment is specific to this data and method. Therefore, it is important to outline some limitations of the results. Although framework (??) is broad, this experiment only analyses portfolios constructed with South African equity returns, and cannot be used to state facts about the portfolio construction process generally. The budget, long-only and maximum weight constraints were all applied for this experiment. Specifically the maximum weight constraint used is \\(\\alpha = 0.1\\). The choice intends to provide a consistent basis for comparison across portfolio-technique pairs and ensures similarity to practical applications. Shares that have missing data were excluded at each rebalancing date with a filter, therefore the MW portfolio, where \\(N = 40\\) may not be representative of the JSE Top 40 index. Transaction costs are ignored due to the liquid nature of the largest stocks, although this is a potential area for future improvement on the backtesting methodology. 7.2 Results Before the results are reported, specific metrics that illustrate the effect of each technique and portfolio need to be introduced. The first is turnover (TO). It measures the magnitude of trading required on each rebalancing date. If there are \\(m\\) rebalancing dates, then the TO is calculated as: \\[\\begin{align} \\text{TO} &amp; = \\frac{6}{(m - 1)} \\sum_{i = 1}^{m - 1} \\sum_{j =1}^{N} |\\hat{w}_{t_i, j}^\\triangle - \\hat{w}_{t_i, j}|, \\end{align}\\] where \\(\\hat{w}_{t_i, j}^\\triangle\\) is the buy-and-hold weight of the \\(j^{th}\\) asset just before the rebalance at time \\(t_i\\). The turnover is annual and one-way only; hence, the scaling factor of \\(\\frac{6}{m-1}\\). For a higher TO, the investor has increased risk when rebalancing that they will not enter into the new portfolio at the current market price. The maximum possible value of the TO is \\(1200\\%\\), and the investor achieves it if they switch from one single stock portfolio to another at every rebalancing date. The next reporting metric is maximum drawdown (MDD), the definition of which requires the notion of cumulative wealth. The investor’s cumulative wealth at time \\(t_j\\) is their return from time \\(t_0\\) until time \\(t_j\\) on a portfolio of one initial unit investment, and it is defined as: \\[\\begin{align*} W_{t_j} &amp;= \\prod_{i = 1}^{j} (1 + \\hat{r}_{t_i}), \\end{align*}\\] where \\(\\hat{r}_{t_i}\\) is the return realised over the interval \\([t_{i - 1}, t_i)\\). The MDD is the biggest loss in cumulative wealth for the entire investment period, and is formulated as: \\[\\begin{align} \\text{MDD} &amp; = \\underset{t_j \\in \\{t_1, ..., t_m\\}}{\\text{argmax}} \\Big \\{ \\underset{t_i \\in \\{t_1, \\text{...}, t_j\\}}{\\text{argmax} \\{W_{t_i} \\}} - W_{t_j} \\Big \\} \\; . \\end{align}\\] MDD is an essential measure for money managers because excessive drawdowns lead to redemptions in their funds. (Magdon-Ismail and Atiya 2004) The last two measures are measures of concentration. As stated earlier, the risk-based investor is making a trade-off between weight concentration and risk concentration. A standard for weight concentration at a rebalancing date, the inverse Herfindahl index, has already been defined. But the IHI is general and could apply to multiple types of weights. For allocation weights the IHI at time \\(t_i\\) is given as: \\[\\begin{align} N^{\\text{eff}}_{t_i} &amp;= \\frac{1}{\\sum_{j = 1}^N w_{t_i, j}^2} \\; , \\end{align}\\] where $N^{}{t_i} $ can be interpreted as the number of equal-weighted stocks the investor’s portfolio is equivalent to. The notation reflects the idea that the IHI represents the number of effective stocks in the portfolio. The upper bound of $N^{}{t_i} $ is \\(N\\) and the lower bound in the presence of a maximum allocation constraint is: \\(({\\lfloor \\frac{1}{\\alpha} \\rfloor \\cdot \\alpha^2 + (1- \\lfloor \\frac{1}{\\alpha}\\rfloor \\cdot \\alpha)^2})^{-1}\\) , which is derived in appendix 3. For the case when \\(\\alpha = 0.1\\) the lower bound is \\(10\\). Risk-weights can be taken instead of capital weights to measure the effectiveness of an asset on portfolio volatility. Since the TRCs sum to the portfolio volatility, the risk contributions can be scaled into risk-weights so that they sum to \\(1\\). The risk-weight for the \\(j^{th}\\) asset at time \\(t_i\\) is given as: \\[\\begin{align} \\text{RW}_{t_i, j} &amp;= \\frac{\\text{TRC}_{t_i, j}}{\\sqrt{w_{t_i}^\\intercal \\Sigma w_{t_i}}}\\; , \\end{align}\\] where the inverse Herfindahl index approach can be applied again. The risk-weight IHI is written as: \\[\\begin{align} N^\\mathrm{rw}_{t_i}(RW_{t_i}) &amp;= \\frac{1}{\\sum_{j = 1}^N \\text{RW}_{t_i, j}^2} \\;. \\end{align}\\] If \\(\\Sigma\\) is positive semi-definite, then the lower bound is \\(1\\) even in the presence of the maximum allocation constraint, because one asset could have a positive weight and considerable volatility. The upper bound is once again \\(N\\). The concentration measures are reported as averages across all of the \\(m\\) rebalancing dates. Let us first discuss the results for the GMV portfolios. The main objective of constructing GMV portfolios is to reduce the out-of-sample volatility of returns. The main aim of each GMV-technique pair is the same, but performance is measured against the GMV-SCM pair. Therefore, it makes sense to define a measure of each GMV-technique pair performance in the same way as Richard and Roncalli (2015), as a volatility reduction over the GMV-SCM pair: \\[\\begin{align} \\mathcal{VR}(w|w_{\\text{gmv-scm}}) &amp; = \\frac{\\sigma(w_{\\text{gmv-scm}}) - \\sigma(w)}{\\sigma(w_{\\text{gmv-scm}})}, \\end{align}\\] where the \\(\\sigma(\\cdot)\\) function measures a portfolio’s volatility. 7.2.1 going to R’ify 7.3 Code 7.3.1 Data reading in and cleaning library(readxl) library(tidyr) library(dplyr) library(lubridate) library(magrittr) library(rlang) library(ggplot2) library(knitr) # sourcing data ------------------------------------------------------------------------------------ weekly_ret &lt;- read_xlsx( &quot;data/data_emlyn.xlsx&quot;, sheet = &quot;Weekly TRets&quot;, na = c(&quot;&quot;, &quot;NaN&quot;) ) ## New names: ## * `` -&gt; ...1 month_ret &lt;- read_xlsx( &quot;data/data_emlyn.xlsx&quot;, sheet = &quot;Monthly TRets&quot;, na = c(&quot;&quot;, &quot;NaN&quot;) ) ## New names: ## * `` -&gt; ...1 alsi_weights &lt;- read_xlsx( &quot;data/data_emlyn.xlsx&quot;, sheet = &quot;ALSI Weights&quot;, na = c(&quot;&quot;, &quot;Nan&quot;) ) ## New names: ## * `` -&gt; ...2 # cleaning data ------------------------------------------------------------------------------------ weekly_ret &lt;- weekly_ret %&gt;% rename(&quot;date&quot; = &quot;...1&quot;) %&gt;% mutate(date = as.Date(.data$date)) %&gt;% pivot_longer(setdiff(colnames(weekly_ret), c(&quot;...1&quot;))) %&gt;% drop_na() %&gt;% arrange(.data$date) %&gt;% mutate(join_col = paste0(month(date), year(date))) month_ret &lt;- month_ret %&gt;% rename(&quot;date&quot; = &quot;...1&quot;) %&gt;% mutate(date = as.Date(.data$date)) %&gt;% pivot_longer(setdiff(colnames(month_ret), c(&quot;...1&quot;))) %&gt;% drop_na() %&gt;% arrange(.data$date) %&gt;% mutate(join_col = paste0(month(date), year(date))) alsi_weights &lt;- alsi_weights %&gt;% rename(&quot;date&quot; = &quot;...2&quot;) %&gt;% select(-.data$SumCheck) %&gt;% mutate(date = as.Date(.data$date) + 15) %&gt;% # weights are at end of month, making start pivot_longer(setdiff(colnames(alsi_weights), c(&quot;SumCheck&quot;, &quot;...2&quot;))) %&gt;% drop_na() %&gt;% arrange(.data$date) %&gt;% mutate(join_col = paste0(month(date), year(date))) # joining data ------------------------------------------------------------------------------------- full_ret &lt;- weekly_ret %&gt;% left_join( month_ret, by = c(&quot;join_col&quot;, &quot;name&quot;), suffix = c(&quot;_week&quot;, &quot;_month&quot;) ) %&gt;% select( date = .data$date_week, .data$name, week_ret = .data$value_week, month_ret = .data$value_month, .data$join_col ) %&gt;% left_join( alsi_weights, by = c(&quot;join_col&quot;, &quot;name&quot;), suffix = c(&quot;_full&quot;, &quot;_weights&quot;) ) %&gt;% select( date = .data$date_full, .data$name, .data$week_ret, .data$month_ret, month_weight_start = .data$value, month_index = .data$join_col ) # keeping complete cases only ---------------------------------------------------------------------- complete_per &lt;- sum(complete.cases(full_ret))/nrow(full_ret) # data is 98.2% complete incomp_weight_per &lt;- sum(full_ret[!complete.cases(full_ret),]$month_weight_start, na.rm = TRUE) / sum(full_ret$month_weight_start, na.rm = TRUE) # but only 0.2% of the weight is in the incomplete data, so it is largely # isolated to the long tail of small stocks that are outside of the # top 40 and 100 and are therefore not needed in this research full_ret &lt;- full_ret[complete.cases(full_ret),] # plot coverage full_ret %&gt;% filter(.data$month_weight_start &gt;= 0) %&gt;% group_by(date) %&gt;% count() %&gt;% ggplot(aes(.data$date, .data$n)) + geom_line() + ggtitle(&quot;coverage through time&quot;) # getting indices ---------------------------------------------------------------------------------- top40_month_weights &lt;- full_ret %&gt;% group_by(.data$month_index) %&gt;% filter(.data$date == min(.data$date)) %&gt;% mutate(size_order = rank(-.data$month_weight_start)) %&gt;% filter(.data$size_order &lt;= 40) %&gt;% mutate(top40_weight = .data$month_weight_start / sum(.data$month_weight_start)) %&gt;% ungroup() %&gt;% select(.data$month_index, .data$name, .data$top40_weight) top100_month_weights &lt;- full_ret %&gt;% group_by(.data$month_index) %&gt;% filter(.data$date == min(.data$date)) %&gt;% mutate(size_order = rank(-.data$month_weight_start)) %&gt;% filter(.data$size_order &lt;= 100) %&gt;% mutate(top100_weight = .data$month_weight_start / sum(.data$month_weight_start)) %&gt;% ungroup() %&gt;% select(.data$month_index, .data$name, .data$top100_weight) full_ret &lt;- full_ret %&gt;% full_join( top40_month_weights, by = c(&quot;month_index&quot;, &quot;name&quot;) ) %&gt;% full_join( top100_month_weights, by = c(&quot;month_index&quot;, &quot;name&quot;) ) %&gt;% select( .data$date, .data$name, .data$week_ret, .data$month_ret, .data$top40_weight, .data$top100_weight, .data$month_index ) %&gt;% replace_na(list(top40_weight = 0, top100_weight = 0)) saveRDS(full_ret, file = &quot;data/full_ret.rds&quot;) head(full_ret, 10) ## # A tibble: 10 x 7 ## date name week_ret month_ret top40_weight top100_weight month_index ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1996-02-02 ABI -0.0314 0.0133 0 0.00104 21996 ## 2 1996-02-02 AXL 0.0436 0.0436 0 0 21996 ## 3 1996-02-02 ACL -0.0886 0.0218 0 0 21996 ## 4 1996-02-02 ACT 0 0.0833 0 0 21996 ## 5 1996-02-02 ADR 0 0.250 0 0.0000499 21996 ## 6 1996-02-02 AEL 0.0208 -0.265 0 0 21996 ## 7 1996-02-02 AEN 0.0455 -0.130 0 0 21996 ## 8 1996-02-02 AFE -0.0545 -0.106 0.00626 0.00598 21996 ## 9 1996-02-02 AFI 0 0.105 0 0.00109 21996 ## 10 1996-02-02 AFL 0 0 0 0 21996 7.3.2 Data preparation library(rlang) library(magrittr) library(dplyr) library(data.table) library(tidyr) full_ret &lt;- readRDS(&quot;data/full_ret.rds&quot;) sample_est_wind &lt;- 400 rebal_est_ranges &lt;- full_ret %&gt;% select(.data$date, .data$month_index) %&gt;% distinct() %&gt;% mutate(start_date = shift(.data$date, sample_est_wind)) %&gt;% mutate(end_date = shift(.data$date, 1)) %&gt;% na.omit() %&gt;% group_by(.data$month_index) %&gt;% filter(.data$date == min(.data$date)) %&gt;% ungroup() %&gt;% select(.data$month_index, .data$start_date, .data$end_date) model_rebal_dat &lt;- tibble(month_index = rebal_est_ranges$month_index, data = list(NULL)) for (i in seq_along(rebal_est_ranges$month_index)) { dat_now &lt;- full_ret %&gt;% filter(.data$date &lt;= rebal_est_ranges[i, ]$end_date &amp; .data$date &gt;= rebal_est_ranges[i, ]$start_date) %&gt;% mutate(month_index = rebal_est_ranges[i, ]$month_index) %&gt;% nest(data = c(&quot;date&quot;, &quot;name&quot;, &quot;week_ret&quot;, &quot;month_ret&quot;, &quot;top40_weight&quot;, &quot;top100_weight&quot;)) model_rebal_dat[i, ] &lt;- dat_now[1, ] } saveRDS(model_rebal_dat, file = &quot;data/model_rebal_dat.rds&quot;) head(model_rebal_dat, 6) ## # A tibble: 6 x 2 ## month_index data ## &lt;chr&gt; &lt;list&gt; ## 1 102003 &lt;tibble [75,749 × 6]&gt; ## 2 112003 &lt;tibble [76,103 × 6]&gt; ## 3 122003 &lt;tibble [76,373 × 6]&gt; ## 4 12004 &lt;tibble [76,634 × 6]&gt; ## 5 22004 &lt;tibble [76,948 × 6]&gt; ## 6 32004 &lt;tibble [77,186 × 6]&gt; References "]
]
